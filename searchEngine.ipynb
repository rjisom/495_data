{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 495 Search engine applied to nf_corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CST 495 Data Science For Search, Spring 2016\n",
    "# @uthors: Richard Isom, Joshua Kim\n",
    "#\n",
    "#  This program was designed to look into tf-idf and bm25 techniques for making a search engine\n",
    "# to test and explore the functionality and user feedback on queries given by volunteer testers\n",
    "#\n",
    "# Medical text obtained from http://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/\n",
    "# Search engine template designed after https://github.com/mattwg/data-science-for-search\n",
    "# Map-Reduce design by CSUMB Big Data capstone project: http://www.csumbbigdata.github.io\n",
    "\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# open file containging data\n",
    "dataFile = \"data/nfcorpus_medical.txt\"\n",
    "with open(dataFile) as f:\n",
    "    r = csv.reader(f, delimiter='\t')\n",
    "    docs = [ x[1] for i,x in enumerate(r) if i > 1 ]\n",
    "    \n",
    "# retrieve results from document data, with k1 and b BM-25 constants\n",
    "def get_results(qry, corpus, k1=1.5, b=0.75):\n",
    "    idx = create_inverted_index(corpus)\n",
    "    n = len(corpus)\n",
    "    d = [len(x.split()) for x in corpus]\n",
    "    d_avg = float(sum(d)) / len(d)                \n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idx:\n",
    "            i = idf(term, idx, n)\n",
    "            for doc in idx[term]:\n",
    "                f = float(idx[term][doc])\n",
    "                score[doc] += i * (( f * (k1 + 1) ) / (f + k1 * (1 - b + (b * (float(d[doc]) / d_avg)))))\n",
    "        \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            # output [0] score, [1] doc_id\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    return results;\n",
    "\n",
    "# inverted index of document data \n",
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                if i in idx[word]:\n",
    "                    # Update document's frequency\n",
    "                    idx[word][i] += 1\n",
    "                else:\n",
    "                    # Add document\n",
    "                    idx[word][i] = 1\n",
    "            else:\n",
    "                # Add term\n",
    "                idx[word] = {i:1}\n",
    "    return idx\n",
    "\n",
    "# inverse document frequency\n",
    "def idf(term, idx, n):\n",
    "    return math.log( float(n) / (1 + len(idx[term])))\n",
    "\n",
    "# bokeh tools for displaying data\n",
    "from bokeh.charts import output_notebook, Scatter, show\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.plotting import ColumnDataSource, figure\n",
    "from bokeh.models import HoverTool, ColorMapper\n",
    "from bokeh.palettes import YlOrRd9\n",
    "\n",
    "print(YlOrRd9)\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "results = get_results('', docs, k1=1.5, b=0.75)\n",
    "\n",
    "x_vals = [float(x[0]) for x in results] \n",
    "y_vals = [len(docs[x[1]].split()) for x in results]\n",
    "d_vals = [docs[x[1]] for x in results]\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"desc\", \"@desc\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=x_vals,y=y_vals,desc=d_vals))\n",
    "p = figure()\n",
    "p.add_tools(hover)\n",
    "p.circle(x_vals, y_vals, size=10, color=\"red\", source=source)\n",
    "show(p)\n",
    "\n",
    "# Set data to be retrieved when query is updated\n",
    "def update(qry, k1, b):\n",
    "    results = get_results(qry, docs, k1, b)\n",
    "    x_vals = [float(x[0]) for x in results] \n",
    "    y_vals = [len(docs[x[1]].split()) for x in results]\n",
    "    d_vals = [docs[x[1]] for x in results]\n",
    "    source.data['x'] = x_vals\n",
    "    source.data['y'] = y_vals\n",
    "    source.data['desc'] = d_vals\n",
    "    push_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interaction box for setting queries and k1 and b constants   \n",
    "from ipywidgets import interact\n",
    "interact(update, qry='cancer', k1=(0.0,2.0,0.05), b=(0.0,1.0,0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Reduce Functions\n",
    "These were tested on our test text document to see how it would work accross hadoop clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mapper\n",
    "def mapper():\n",
    "    for line in sys.stdin:\n",
    "        data = line.strip().split(\" \")\n",
    "        words = data\n",
    "        for word in words:\t\n",
    "            print \"{0}\\t{1}\".format(word,\"1\")\n",
    "mapper()\n",
    "\n",
    "# Reducer\n",
    "wordCount = {}\n",
    "def reducer():    \n",
    "    for line in sys.stdin:        \n",
    "        line = line.strip()\n",
    "        word, count = line.split(\"\\t\",1)\n",
    "        try:\n",
    "            count = int(count)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        try:\n",
    "            wordCount[word] = wordCount[word] + count\n",
    "        except:\n",
    "            wordCount[word] =count \n",
    "    for word in wordCount.keys():\n",
    "        print \"{0}\\t{1}\".format(word,wordCount[word])\n",
    "reducer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
